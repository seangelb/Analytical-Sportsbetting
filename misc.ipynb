{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import datetime\n",
    "import algorithms\n",
    "import data_clean\n",
    "import simulations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "df = data_clean.do(data_clean)\n",
    "df = algorithms.ml_probabilities(df)\n",
    "df_historic_win_data = data_clean.clean_data(\"spreadspoke_scores.csv\", \"nfl_teams.csv\", \"1990-9-10\") #winners by spread since\n",
    "#win_dict = algorithms.win_percent(df_historic_win_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# start_date, end_date = simulations.historic_win_set(2018,11,15, 2017, 9, 10)\n",
    "# my_sim = simulations.Simulations(1000,0.05, -3, start_date, end_date) #spread is negative\n",
    "# my_sim.simulate_v2(df_historic_win_data,df,algorithms)\n",
    "# \n",
    "# "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# x = my_sim.current_amount"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "start_date, end_date = simulations.historic_win_set(2020,11,15,2009,9,10)\n",
    "min_ev = [.05]\n",
    "max_spread = [-15]\n",
    "df_results = pd.DataFrame()\n",
    "for ev in min_ev:\n",
    "    for spread in max_spread:\n",
    "        my_sim = simulations.Simulations(1000,ev, spread, start_date, end_date) #spread is negative\n",
    "        my_sim.simulate_v2(df_historic_win_data,df,algorithms)\n",
    "        results = {'Amount' : round(my_sim.current_amount,2),'Amount_EV' : round(my_sim.current_ev,2), 'Max_Spread': spread,\n",
    "                                                     'EV' : ev, 'Bet_Count': my_sim.bet}\n",
    "        df_results = df_results.append(results, ignore_index=True)\n",
    "\n",
    "\n",
    "        my_file = \"test_10.csv\"\n",
    "        df_results.to_csv(my_file, header=True, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0e5570836756>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Amount\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   5291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5292\u001b[0m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5293\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5295\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1558\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1560\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Amount'"
     ],
     "ename": "KeyError",
     "evalue": "'Amount'",
     "output_type": "error"
    }
   ],
   "source": [
    "df_results = df_results.sort_values(by=\"Amount\", ascending=False)\n",
    "df_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "import algorithms\n",
    "import data_clean\n",
    "import simulations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "df = data_clean.clean_data(\"spreadspoke_scores.csv\", \"nfl_teams.csv\", \"2009-9-10\")\n",
    "df = data_clean.make_simple(df)\n",
    "\n",
    "df_teams = pd.read_csv(\"nfl_teams.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(6862, 19)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "scores = \"NFL_spread_since2009.csv\"\n",
    "df_spread = pd.read_csv(scores)\n",
    "\n",
    "print(df_spread.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def remove_misc_teams(bad_data, df_ml):  # used on ml df. Removes random teams from dataset\n",
    "    df_ml = df_ml[~df_ml['team'].isin(bad_data)]\n",
    "    df_ml = df_ml[~df_ml['opp_team'].isin(bad_data)]\n",
    "    return df_ml"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "bad_data = ['NFC', 'AFC', 'Team Rice', 'Team Sanders', 'Team Carter', 'Team Irvin']\n",
    "df_spread = remove_misc_teams(bad_data, df_spread)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(6856, 19)\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "                              key      date   H/A          team     opp_team  \\\n0          20090913_Miami_Atlanta  20090913  away         Miami      Atlanta   \n1          20090913_Miami_Atlanta  20090913  home       Atlanta        Miami   \n2  20090913_Kansas City_Baltimore  20090913  away   Kansas City    Baltimore   \n3  20090913_Kansas City_Baltimore  20090913  home     Baltimore  Kansas City   \n4  20090913_Philadelphia_Carolina  20090913  away  Philadelphia     Carolina   \n\n  pinnacle_line pinnacle_odds 5dimes_line 5dimes_odds heritage_line  \\\n0            +4          -104          +4        -104           NaN   \n1            -4          -104          -4        -106           NaN   \n2           +13          -112       +12.5        -105           NaN   \n3           -13          +104       -12.5        -105           NaN   \n4            -1          -120        -2.5        -109           NaN   \n\n  heritage_odds bovada_line bovada_odds betonline_line betonline_odds  \\\n0           NaN          +4        -105             +4           -110   \n1           NaN          -4        -115             -4           -110   \n2           NaN         +13        -105            +13           -110   \n3           NaN         -13        -115            -13           -110   \n4           NaN          -3        +100           -2.5           -110   \n\n   bet365_line  bet365_odds bodog_line bodog_odds  \n0          NaN          NaN         +4       -110  \n1          NaN          NaN         -4       -110  \n2          NaN          NaN        +13       -110  \n3          NaN          NaN        -13       -110  \n4          NaN          NaN       -2.5       -110  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>key</th>\n      <th>date</th>\n      <th>H/A</th>\n      <th>team</th>\n      <th>opp_team</th>\n      <th>pinnacle_line</th>\n      <th>pinnacle_odds</th>\n      <th>5dimes_line</th>\n      <th>5dimes_odds</th>\n      <th>heritage_line</th>\n      <th>heritage_odds</th>\n      <th>bovada_line</th>\n      <th>bovada_odds</th>\n      <th>betonline_line</th>\n      <th>betonline_odds</th>\n      <th>bet365_line</th>\n      <th>bet365_odds</th>\n      <th>bodog_line</th>\n      <th>bodog_odds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20090913_Miami_Atlanta</td>\n      <td>20090913</td>\n      <td>away</td>\n      <td>Miami</td>\n      <td>Atlanta</td>\n      <td>+4</td>\n      <td>-104</td>\n      <td>+4</td>\n      <td>-104</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>+4</td>\n      <td>-105</td>\n      <td>+4</td>\n      <td>-110</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>+4</td>\n      <td>-110</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20090913_Miami_Atlanta</td>\n      <td>20090913</td>\n      <td>home</td>\n      <td>Atlanta</td>\n      <td>Miami</td>\n      <td>-4</td>\n      <td>-104</td>\n      <td>-4</td>\n      <td>-106</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4</td>\n      <td>-115</td>\n      <td>-4</td>\n      <td>-110</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4</td>\n      <td>-110</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20090913_Kansas City_Baltimore</td>\n      <td>20090913</td>\n      <td>away</td>\n      <td>Kansas City</td>\n      <td>Baltimore</td>\n      <td>+13</td>\n      <td>-112</td>\n      <td>+12.5</td>\n      <td>-105</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>+13</td>\n      <td>-105</td>\n      <td>+13</td>\n      <td>-110</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>+13</td>\n      <td>-110</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20090913_Kansas City_Baltimore</td>\n      <td>20090913</td>\n      <td>home</td>\n      <td>Baltimore</td>\n      <td>Kansas City</td>\n      <td>-13</td>\n      <td>+104</td>\n      <td>-12.5</td>\n      <td>-105</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-13</td>\n      <td>-115</td>\n      <td>-13</td>\n      <td>-110</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-13</td>\n      <td>-110</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20090913_Philadelphia_Carolina</td>\n      <td>20090913</td>\n      <td>away</td>\n      <td>Philadelphia</td>\n      <td>Carolina</td>\n      <td>-1</td>\n      <td>-120</td>\n      <td>-2.5</td>\n      <td>-109</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-3</td>\n      <td>+100</td>\n      <td>-2.5</td>\n      <td>-110</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-2.5</td>\n      <td>-110</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 7
    }
   ],
   "source": [
    "print(df_spread.shape)\n",
    "df_spread.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def add_spread_team_id(self, df_ml, df_teams,\n",
    "                   csvfile=\"team_key_value_pairs.csv\"):  # changes team names to team id by merged df_ml, df_team, and a key value pair table\n",
    "    df_kv = pd.read_csv(csvfile)\n",
    "    df_ml = df_ml.merge(df_kv, left_on='team', right_on='team', how='left')\n",
    "    df_ml = df_ml.merge(df_teams[['team_name', 'team_id']], left_on='team_name', right_on='team_name', how='left')\n",
    "    df_ml = df_ml.drop(\"team_name\", axis=1)\n",
    "    df_ml = df_ml.merge(df_kv, left_on='opp_team', right_on='team', how='left')\n",
    "    df_ml = df_ml.merge(df_teams[['team_name', 'team_id']], left_on='team_name', right_on='team_name', how='inner')\n",
    "    df_ml = df_ml.drop([\"team_x\", \"opp_team\", \"team_name\", \"team_y\", \"team_name\"], axis=1)\n",
    "    df_ml = df_ml.rename(columns={\"team_id_x\": \"home\", \"team_id_y\": \"away\"})\n",
    "\n",
    "    df_ml['spread'] = df_ml[['pinnacle_line', '5dimes_line', 'heritage_line\t', 'betonline_line', 'bet365_line', 'bodog_line']].values.tolist()\n",
    "    df_ml = df_ml.drop(['pinnacle_line', '5dimes_line', 'heritage_line\t', 'betonline_line', 'bet365_line', 'bodog_line'], axis=1)\n",
    "    df_ml['spread'] = df_ml['spread'].apply(lambda x: [i for i in x if i == i])\n",
    "    df_ml['spread'] = df_ml['spread'].apply(lambda x: self.median_split_special_case(x))\n",
    "    # use median of the lines for the moneyline (will try out other methods in future). This is mostly for backtesting.\n",
    "    df_ml_home = df_ml[\n",
    "        df_ml['H/A'] == 'home']  # I would do if postive, highest ML, if negative, then number closest to 0.\n",
    "    df_ml_away = df_ml[df_ml['H/A'] == 'away']\n",
    "    df_ml = df_ml_home.merge(df_ml_away[['key', 'moneyline']], on=\"key\")\n",
    "    df_ml = df_ml.rename(columns={\"moneyline_x\": \"home_spread\", \"moneyline_y\": \"away_spread\"})\n",
    "    df_ml['date'] = pd.to_datetime(df_ml['date'], format='%Y%m%d')  # date\n",
    "    return df_ml\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "     schedule_date home  score_home away  score_away team_favorite_id  \\\n0       2009-09-13  ARI        16.0   SF        20.0              ARI   \n1       2009-09-13  ATL        19.0  MIA         7.0              ATL   \n2       2009-09-13  BAL        38.0   KC        24.0              BAL   \n3       2009-09-13  CAR        10.0  PHI        38.0              PHI   \n4       2009-09-13  CIN         7.0  DEN        12.0              CIN   \n...            ...  ...         ...  ...         ...              ...   \n3050    2020-11-01   KC        35.0  NYJ         9.0               KC   \n3051    2020-11-01  MIA        28.0  LAR        17.0              LAR   \n3052    2020-11-01  PHI        23.0  DAL         9.0              PHI   \n3053    2020-11-01  SEA        37.0   SF        27.0              SEA   \n3054    2020-11-02  NYG        23.0   TB        25.0               TB   \n\n      spread_favorite  \n0                -4.5  \n1                -4.0  \n2               -13.0  \n3                -2.5  \n4                -5.0  \n...               ...  \n3050            -19.5  \n3051             -3.5  \n3052            -11.5  \n3053             -3.0  \n3054            -12.5  \n\n[3055 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>schedule_date</th>\n      <th>home</th>\n      <th>score_home</th>\n      <th>away</th>\n      <th>score_away</th>\n      <th>team_favorite_id</th>\n      <th>spread_favorite</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2009-09-13</td>\n      <td>ARI</td>\n      <td>16.0</td>\n      <td>SF</td>\n      <td>20.0</td>\n      <td>ARI</td>\n      <td>-4.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2009-09-13</td>\n      <td>ATL</td>\n      <td>19.0</td>\n      <td>MIA</td>\n      <td>7.0</td>\n      <td>ATL</td>\n      <td>-4.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2009-09-13</td>\n      <td>BAL</td>\n      <td>38.0</td>\n      <td>KC</td>\n      <td>24.0</td>\n      <td>BAL</td>\n      <td>-13.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2009-09-13</td>\n      <td>CAR</td>\n      <td>10.0</td>\n      <td>PHI</td>\n      <td>38.0</td>\n      <td>PHI</td>\n      <td>-2.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2009-09-13</td>\n      <td>CIN</td>\n      <td>7.0</td>\n      <td>DEN</td>\n      <td>12.0</td>\n      <td>CIN</td>\n      <td>-5.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3050</th>\n      <td>2020-11-01</td>\n      <td>KC</td>\n      <td>35.0</td>\n      <td>NYJ</td>\n      <td>9.0</td>\n      <td>KC</td>\n      <td>-19.5</td>\n    </tr>\n    <tr>\n      <th>3051</th>\n      <td>2020-11-01</td>\n      <td>MIA</td>\n      <td>28.0</td>\n      <td>LAR</td>\n      <td>17.0</td>\n      <td>LAR</td>\n      <td>-3.5</td>\n    </tr>\n    <tr>\n      <th>3052</th>\n      <td>2020-11-01</td>\n      <td>PHI</td>\n      <td>23.0</td>\n      <td>DAL</td>\n      <td>9.0</td>\n      <td>PHI</td>\n      <td>-11.5</td>\n    </tr>\n    <tr>\n      <th>3053</th>\n      <td>2020-11-01</td>\n      <td>SEA</td>\n      <td>37.0</td>\n      <td>SF</td>\n      <td>27.0</td>\n      <td>SEA</td>\n      <td>-3.0</td>\n    </tr>\n    <tr>\n      <th>3054</th>\n      <td>2020-11-02</td>\n      <td>NYG</td>\n      <td>23.0</td>\n      <td>TB</td>\n      <td>25.0</td>\n      <td>TB</td>\n      <td>-12.5</td>\n    </tr>\n  </tbody>\n</table>\n<p>3055 rows Ã— 7 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 48
    }
   ],
   "source": [
    "import datetime\n",
    "import algorithms\n",
    "import data_clean\n",
    "import simulations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "df = data_clean.clean_data(\"spreadspoke_scores.csv\", \"nfl_teams.csv\", \"2009-9-10\")\n",
    "df = data_clean.make_simple(df)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "df_spread = pd.read_csv(\"NFL_spread_since2009.csv\")\n",
    "bad_data = ['NFC', 'AFC', 'Team Rice', 'Team Sanders', 'Team Carter', 'Team Irvin']\n",
    "df_spread = data_clean.remove_misc_teams(bad_data, df_spread)\n",
    "df_ml = pd.read_csv(\"NFL_moneylines.csv\")\n",
    "df_ml = data_clean.remove_misc_teams(bad_data, df_ml)\n",
    "df_ml = data_clean.add_ml_team_id(data_clean, df_ml, df_teams)\n",
    "#df_spread = data_clean.add_spread_team_id(data_clean, df_spread, df_teams)\n",
    "# df_test1 = data_clean.update_spreads(df, df_spread)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "def add_spread_team_id(df_ml, df_teams,\n",
    "                       csvfile=\"team_key_value_pairs.csv\"):  # changes team names to team id by merged df_ml, df_team, and a key value pair table\n",
    "    df_kv = pd.read_csv(csvfile)\n",
    "    df_ml = df_ml.merge(df_kv, left_on='team', right_on='team', how='left')\n",
    "    df_ml = df_ml.merge(df_teams[['team_name', 'team_id']], left_on='team_name', right_on='team_name', how='left')\n",
    "    df_ml = df_ml.drop(\"team_name\", axis=1)\n",
    "    df_ml = df_ml.merge(df_kv, left_on='opp_team', right_on='team', how='left')\n",
    "    df_ml = df_ml.merge(df_teams[['team_name', 'team_id']], left_on='team_name', right_on='team_name', how='inner')\n",
    "    df_ml = df_ml.drop([\"team_x\", \"opp_team\", \"team_name\", \"team_y\", \"team_name\"], axis=1)\n",
    "    df_ml = df_ml.rename(columns={\"team_id_x\": \"home\", \"team_id_y\": \"away\"})\n",
    "\n",
    "    df_ml['spread'] = df_ml[['pinnacle_line', '5dimes_line', 'heritage_line', 'betonline_line', 'bet365_line',\n",
    "                             'bodog_line']].values.tolist()\n",
    "    df_ml = df_ml.drop(['pinnacle_line', '5dimes_line', 'heritage_line', 'betonline_line', 'bet365_line', 'bodog_line'],\n",
    "                       axis=1)\n",
    "    df_ml['spread'] = df_ml['spread'].apply(lambda x: [float(i) for i in x if is_float(i)])\n",
    "    df_ml['spread'] = df_ml['spread'].apply(lambda x: [i for i in x if i == i])\n",
    "    df_ml['spread'] = df_ml['spread'].apply(lambda x: np.median(x))\n",
    "    df_ml_home = df_ml[\n",
    "    df_ml['H/A'] == 'home']  # I would do if postive, highest ML, if negative, then number closest to 0.\n",
    "    df_ml_away = df_ml[df_ml['H/A'] == 'away']\n",
    "    \n",
    "    df_ml = df_ml_home.merge(df_ml_away[['key', 'spread']], on=\"key\")\n",
    "    df_ml = df_ml.rename(columns={\"spread_x\": \"home_spread\", \"spread_y\": \"away_spread\"})\n",
    "    df_ml['date'] = pd.to_datetime(df_ml['date'], format='%Y%m%d')\n",
    "    \n",
    "    df_ml['spread_favorite'] = np.where(df_ml['home_spread'] >= df_ml['away_spread'], df_ml['away_spread'],\n",
    "                                        df_ml['home_spread'])\n",
    "    df_ml['team_favorite_id'] = np.where(df_ml['home_spread'] >= df_ml['away_spread'], df_ml['away'], df_ml['home'])\n",
    "    df_ml = df_ml[['date', 'home', 'away', 'team_favorite_id', 'spread_favorite']]\n",
    "    return df_ml"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "def is_float(n):  # checks to see if number is a real number else returns false\n",
    "    try:\n",
    "        float(n)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "        date home away team_favorite_id  spread_favorite\n0 2009-09-27   NE  ATL               NE            -4.50\n1 2009-10-11   SF  ATL               SF            -1.00\n2 2009-11-02   NO  ATL               NO           -11.00\n3 2009-11-15  CAR  ATL              ATL            -1.00\n4 2009-11-22  NYG  ATL              NYG            -7.25",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>home</th>\n      <th>away</th>\n      <th>team_favorite_id</th>\n      <th>spread_favorite</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2009-09-27</td>\n      <td>NE</td>\n      <td>ATL</td>\n      <td>NE</td>\n      <td>-4.50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2009-10-11</td>\n      <td>SF</td>\n      <td>ATL</td>\n      <td>SF</td>\n      <td>-1.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2009-11-02</td>\n      <td>NO</td>\n      <td>ATL</td>\n      <td>NO</td>\n      <td>-11.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2009-11-15</td>\n      <td>CAR</td>\n      <td>ATL</td>\n      <td>ATL</td>\n      <td>-1.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2009-11-22</td>\n      <td>NYG</td>\n      <td>ATL</td>\n      <td>NYG</td>\n      <td>-7.25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 69
    }
   ],
   "source": [
    "df_teams = pd.read_csv(\"nfl_teams.csv\")\n",
    "\n",
    "df_ml = add_spread_team_id(df_spread, df_teams)\n",
    "df_ml.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%    \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "                               key       date   H/A pinnacle_odds 5dimes_odds  \\\n0     20090927_Atlanta_New England 2009-09-27  home          +101        -102   \n1   20091011_Atlanta_San Francisco 2009-10-11  home          +105        +100   \n2     20091102_Atlanta_New Orleans 2009-11-02  home          +101        +110   \n3        20091115_Atlanta_Carolina 2009-11-15  home          -108      PK-105   \n4     20091122_Atlanta_N.Y. Giants 2009-11-22  home          -110        +105   \n5       20091220_Atlanta_N.Y. Jets 2009-12-20  home          +103        -110   \n6       20100103_Atlanta_Tampa Bay 2010-01-03  home          -108        +105   \n7           20100827_Atlanta_Miami 2010-08-27  home          -115        -115   \n8    20100902_Atlanta_Jacksonville 2010-09-02  home          +101        +100   \n9      20100912_Atlanta_Pittsburgh 2010-09-12  home          -102        -102   \n10      20101010_Atlanta_Cleveland 2010-10-10  home          -103        -105   \n11    20101121_Atlanta_Los Angeles 2010-11-21  home          -111        -110   \n12      20101205_Atlanta_Tampa Bay 2010-12-05  home          -112        -112   \n13       20101212_Atlanta_Carolina 2010-12-12  home          -106        -105   \n14        20101219_Atlanta_Seattle 2010-12-19  home          -106        -104   \n15   20110819_Atlanta_Jacksonville 2011-08-19  home          +100        -130   \n16     20110827_Atlanta_Pittsburgh 2011-08-27  home          +104        -115   \n17        20110911_Atlanta_Chicago 2011-09-11  home          +101        -107   \n18      20110925_Atlanta_Tampa Bay 2011-09-25  home          -108        -104   \n19        20111002_Atlanta_Seattle 2011-10-02  home          -104        -105   \n20        20111023_Atlanta_Detroit 2011-10-23  home          -105        -105   \n21   20111106_Atlanta_Indianapolis 2011-11-06  home          +103        +102   \n22        20111204_Atlanta_Houston 2011-12-04  home          +104        -103   \n23       20111211_Atlanta_Carolina 2011-12-11  home          -119        -115   \n24    20111226_Atlanta_New Orleans 2011-12-26  home          -103        -107   \n\n   heritage_odds bovada_line bovada_odds betonline_odds  bet365_odds  \\\n0            NaN        -4.5        -110           -110          NaN   \n1            NaN          -1        -110           -110          NaN   \n2            NaN       -11.5        -110           -110          NaN   \n3            NaN          +2        -110           -110          NaN   \n4            NaN          -7        -115           -110          NaN   \n5            NaN          -5        -110           -110          NaN   \n6            NaN          +2        +120           +100          NaN   \n7            NaN        -2.5        -110           -115          NaN   \n8            NaN          -3        -105           -105          NaN   \n9            NaN          +2        -110           -110          NaN   \n10           NaN          +3        +100           -105          NaN   \n11           NaN          +3        +125           -115          NaN   \n12           NaN          +3        +100           -120          NaN   \n13           NaN          +8        -110           -120          NaN   \n14           NaN          +7        -115           -110          NaN   \n15           NaN          -3        +110           +100          NaN   \n16           NaN          -3        +105           +105          NaN   \n17           NaN          +3        -125           -110          NaN   \n18           NaN          +1        -115           -110          NaN   \n19           NaN          +6        +100           -110          NaN   \n20           NaN        -4.5        -110           -110          NaN   \n21          -120          +7        -105           -105          NaN   \n22          -110          +2        -105           -105          NaN   \n23          -125          +3        -115           +110          NaN   \n24          -110        -7.5        -105           -110          NaN   \n\n   bodog_odds home away  home_spread  away_spread  spread_favorite  \\\n0        -110   NE  ATL        -4.50         4.50            -4.50   \n1      PK-110   SF  ATL        -1.00         1.00            -1.00   \n2        -110   NO  ATL       -11.00        11.00           -11.00   \n3        -110  CAR  ATL         1.00        -1.00            -1.00   \n4        -115  NYG  ATL        -7.25         7.25            -7.25   \n5        -110  NYJ  ATL        -5.00         5.00            -5.00   \n6        -120   TB  ATL         2.75        -2.75            -2.75   \n7        -120  MIA  ATL        -2.50         2.50            -2.50   \n8        -105  JAX  ATL        -3.00         3.00            -3.00   \n9        -110  PIT  ATL         1.00        -1.00            -1.00   \n10       -110  CLE  ATL         3.00        -3.00            -3.00   \n11       -115  LAR  ATL         3.50        -3.50            -3.50   \n12       -115   TB  ATL         3.00        -3.00            -3.00   \n13       -110  CAR  ATL         7.00        -7.00            -7.00   \n14       -110  SEA  ATL         5.50        -5.50            -5.50   \n15       +100  JAX  ATL        -3.00         3.00            -3.00   \n16       +100  PIT  ATL        -3.00         3.00            -3.00   \n17       -110  CHI  ATL         1.50        -1.50            -1.50   \n18       -110   TB  ATL        -1.00         1.00            -1.00   \n19       -110  SEA  ATL         6.00        -6.00            -6.00   \n20       -110  DET  ATL        -4.50         4.50            -4.50   \n21       -105  IND  ATL         6.50        -6.50            -6.50   \n22       -110  HOU  ATL         1.50        -1.50            -1.50   \n23       -120  CAR  ATL         3.00        -3.00            -3.00   \n24       -110   NO  ATL        -7.00         7.00            -7.00   \n\n   favorite_team_id  \n0                NE  \n1                SF  \n2                NO  \n3               ATL  \n4               NYG  \n5               NYJ  \n6               ATL  \n7               MIA  \n8               JAX  \n9               ATL  \n10              ATL  \n11              ATL  \n12              ATL  \n13              ATL  \n14              ATL  \n15              JAX  \n16              PIT  \n17              ATL  \n18               TB  \n19              ATL  \n20              DET  \n21              ATL  \n22              ATL  \n23              ATL  \n24               NO  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>key</th>\n      <th>date</th>\n      <th>H/A</th>\n      <th>pinnacle_odds</th>\n      <th>5dimes_odds</th>\n      <th>heritage_odds</th>\n      <th>bovada_line</th>\n      <th>bovada_odds</th>\n      <th>betonline_odds</th>\n      <th>bet365_odds</th>\n      <th>bodog_odds</th>\n      <th>home</th>\n      <th>away</th>\n      <th>home_spread</th>\n      <th>away_spread</th>\n      <th>spread_favorite</th>\n      <th>favorite_team_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20090927_Atlanta_New England</td>\n      <td>2009-09-27</td>\n      <td>home</td>\n      <td>+101</td>\n      <td>-102</td>\n      <td>NaN</td>\n      <td>-4.5</td>\n      <td>-110</td>\n      <td>-110</td>\n      <td>NaN</td>\n      <td>-110</td>\n      <td>NE</td>\n      <td>ATL</td>\n      <td>-4.50</td>\n      <td>4.50</td>\n      <td>-4.50</td>\n      <td>NE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20091011_Atlanta_San Francisco</td>\n      <td>2009-10-11</td>\n      <td>home</td>\n      <td>+105</td>\n      <td>+100</td>\n      <td>NaN</td>\n      <td>-1</td>\n      <td>-110</td>\n      <td>-110</td>\n      <td>NaN</td>\n      <td>PK-110</td>\n      <td>SF</td>\n      <td>ATL</td>\n      <td>-1.00</td>\n      <td>1.00</td>\n      <td>-1.00</td>\n      <td>SF</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20091102_Atlanta_New Orleans</td>\n      <td>2009-11-02</td>\n      <td>home</td>\n      <td>+101</td>\n      <td>+110</td>\n      <td>NaN</td>\n      <td>-11.5</td>\n      <td>-110</td>\n      <td>-110</td>\n      <td>NaN</td>\n      <td>-110</td>\n      <td>NO</td>\n      <td>ATL</td>\n      <td>-11.00</td>\n      <td>11.00</td>\n      <td>-11.00</td>\n      <td>NO</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20091115_Atlanta_Carolina</td>\n      <td>2009-11-15</td>\n      <td>home</td>\n      <td>-108</td>\n      <td>PK-105</td>\n      <td>NaN</td>\n      <td>+2</td>\n      <td>-110</td>\n      <td>-110</td>\n      <td>NaN</td>\n      <td>-110</td>\n      <td>CAR</td>\n      <td>ATL</td>\n      <td>1.00</td>\n      <td>-1.00</td>\n      <td>-1.00</td>\n      <td>ATL</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20091122_Atlanta_N.Y. Giants</td>\n      <td>2009-11-22</td>\n      <td>home</td>\n      <td>-110</td>\n      <td>+105</td>\n      <td>NaN</td>\n      <td>-7</td>\n      <td>-115</td>\n      <td>-110</td>\n      <td>NaN</td>\n      <td>-115</td>\n      <td>NYG</td>\n      <td>ATL</td>\n      <td>-7.25</td>\n      <td>7.25</td>\n      <td>-7.25</td>\n      <td>NYG</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>20091220_Atlanta_N.Y. Jets</td>\n      <td>2009-12-20</td>\n      <td>home</td>\n      <td>+103</td>\n      <td>-110</td>\n      <td>NaN</td>\n      <td>-5</td>\n      <td>-110</td>\n      <td>-110</td>\n      <td>NaN</td>\n      <td>-110</td>\n      <td>NYJ</td>\n      <td>ATL</td>\n      <td>-5.00</td>\n      <td>5.00</td>\n      <td>-5.00</td>\n      <td>NYJ</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>20100103_Atlanta_Tampa Bay</td>\n      <td>2010-01-03</td>\n      <td>home</td>\n      <td>-108</td>\n      <td>+105</td>\n      <td>NaN</td>\n      <td>+2</td>\n      <td>+120</td>\n      <td>+100</td>\n      <td>NaN</td>\n      <td>-120</td>\n      <td>TB</td>\n      <td>ATL</td>\n      <td>2.75</td>\n      <td>-2.75</td>\n      <td>-2.75</td>\n      <td>ATL</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>20100827_Atlanta_Miami</td>\n      <td>2010-08-27</td>\n      <td>home</td>\n      <td>-115</td>\n      <td>-115</td>\n      <td>NaN</td>\n      <td>-2.5</td>\n      <td>-110</td>\n      <td>-115</td>\n      <td>NaN</td>\n      <td>-120</td>\n      <td>MIA</td>\n      <td>ATL</td>\n      <td>-2.50</td>\n      <td>2.50</td>\n      <td>-2.50</td>\n      <td>MIA</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>20100902_Atlanta_Jacksonville</td>\n      <td>2010-09-02</td>\n      <td>home</td>\n      <td>+101</td>\n      <td>+100</td>\n      <td>NaN</td>\n      <td>-3</td>\n      <td>-105</td>\n      <td>-105</td>\n      <td>NaN</td>\n      <td>-105</td>\n      <td>JAX</td>\n      <td>ATL</td>\n      <td>-3.00</td>\n      <td>3.00</td>\n      <td>-3.00</td>\n      <td>JAX</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>20100912_Atlanta_Pittsburgh</td>\n      <td>2010-09-12</td>\n      <td>home</td>\n      <td>-102</td>\n      <td>-102</td>\n      <td>NaN</td>\n      <td>+2</td>\n      <td>-110</td>\n      <td>-110</td>\n      <td>NaN</td>\n      <td>-110</td>\n      <td>PIT</td>\n      <td>ATL</td>\n      <td>1.00</td>\n      <td>-1.00</td>\n      <td>-1.00</td>\n      <td>ATL</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>20101010_Atlanta_Cleveland</td>\n      <td>2010-10-10</td>\n      <td>home</td>\n      <td>-103</td>\n      <td>-105</td>\n      <td>NaN</td>\n      <td>+3</td>\n      <td>+100</td>\n      <td>-105</td>\n      <td>NaN</td>\n      <td>-110</td>\n      <td>CLE</td>\n      <td>ATL</td>\n      <td>3.00</td>\n      <td>-3.00</td>\n      <td>-3.00</td>\n      <td>ATL</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>20101121_Atlanta_Los Angeles</td>\n      <td>2010-11-21</td>\n      <td>home</td>\n      <td>-111</td>\n      <td>-110</td>\n      <td>NaN</td>\n      <td>+3</td>\n      <td>+125</td>\n      <td>-115</td>\n      <td>NaN</td>\n      <td>-115</td>\n      <td>LAR</td>\n      <td>ATL</td>\n      <td>3.50</td>\n      <td>-3.50</td>\n      <td>-3.50</td>\n      <td>ATL</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>20101205_Atlanta_Tampa Bay</td>\n      <td>2010-12-05</td>\n      <td>home</td>\n      <td>-112</td>\n      <td>-112</td>\n      <td>NaN</td>\n      <td>+3</td>\n      <td>+100</td>\n      <td>-120</td>\n      <td>NaN</td>\n      <td>-115</td>\n      <td>TB</td>\n      <td>ATL</td>\n      <td>3.00</td>\n      <td>-3.00</td>\n      <td>-3.00</td>\n      <td>ATL</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>20101212_Atlanta_Carolina</td>\n      <td>2010-12-12</td>\n      <td>home</td>\n      <td>-106</td>\n      <td>-105</td>\n      <td>NaN</td>\n      <td>+8</td>\n      <td>-110</td>\n      <td>-120</td>\n      <td>NaN</td>\n      <td>-110</td>\n      <td>CAR</td>\n      <td>ATL</td>\n      <td>7.00</td>\n      <td>-7.00</td>\n      <td>-7.00</td>\n      <td>ATL</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>20101219_Atlanta_Seattle</td>\n      <td>2010-12-19</td>\n      <td>home</td>\n      <td>-106</td>\n      <td>-104</td>\n      <td>NaN</td>\n      <td>+7</td>\n      <td>-115</td>\n      <td>-110</td>\n      <td>NaN</td>\n      <td>-110</td>\n      <td>SEA</td>\n      <td>ATL</td>\n      <td>5.50</td>\n      <td>-5.50</td>\n      <td>-5.50</td>\n      <td>ATL</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>20110819_Atlanta_Jacksonville</td>\n      <td>2011-08-19</td>\n      <td>home</td>\n      <td>+100</td>\n      <td>-130</td>\n      <td>NaN</td>\n      <td>-3</td>\n      <td>+110</td>\n      <td>+100</td>\n      <td>NaN</td>\n      <td>+100</td>\n      <td>JAX</td>\n      <td>ATL</td>\n      <td>-3.00</td>\n      <td>3.00</td>\n      <td>-3.00</td>\n      <td>JAX</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>20110827_Atlanta_Pittsburgh</td>\n      <td>2011-08-27</td>\n      <td>home</td>\n      <td>+104</td>\n      <td>-115</td>\n      <td>NaN</td>\n      <td>-3</td>\n      <td>+105</td>\n      <td>+105</td>\n      <td>NaN</td>\n      <td>+100</td>\n      <td>PIT</td>\n      <td>ATL</td>\n      <td>-3.00</td>\n      <td>3.00</td>\n      <td>-3.00</td>\n      <td>PIT</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>20110911_Atlanta_Chicago</td>\n      <td>2011-09-11</td>\n      <td>home</td>\n      <td>+101</td>\n      <td>-107</td>\n      <td>NaN</td>\n      <td>+3</td>\n      <td>-125</td>\n      <td>-110</td>\n      <td>NaN</td>\n      <td>-110</td>\n      <td>CHI</td>\n      <td>ATL</td>\n      <td>1.50</td>\n      <td>-1.50</td>\n      <td>-1.50</td>\n      <td>ATL</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>20110925_Atlanta_Tampa Bay</td>\n      <td>2011-09-25</td>\n      <td>home</td>\n      <td>-108</td>\n      <td>-104</td>\n      <td>NaN</td>\n      <td>+1</td>\n      <td>-115</td>\n      <td>-110</td>\n      <td>NaN</td>\n      <td>-110</td>\n      <td>TB</td>\n      <td>ATL</td>\n      <td>-1.00</td>\n      <td>1.00</td>\n      <td>-1.00</td>\n      <td>TB</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>20111002_Atlanta_Seattle</td>\n      <td>2011-10-02</td>\n      <td>home</td>\n      <td>-104</td>\n      <td>-105</td>\n      <td>NaN</td>\n      <td>+6</td>\n      <td>+100</td>\n      <td>-110</td>\n      <td>NaN</td>\n      <td>-110</td>\n      <td>SEA</td>\n      <td>ATL</td>\n      <td>6.00</td>\n      <td>-6.00</td>\n      <td>-6.00</td>\n      <td>ATL</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>20111023_Atlanta_Detroit</td>\n      <td>2011-10-23</td>\n      <td>home</td>\n      <td>-105</td>\n      <td>-105</td>\n      <td>NaN</td>\n      <td>-4.5</td>\n      <td>-110</td>\n      <td>-110</td>\n      <td>NaN</td>\n      <td>-110</td>\n      <td>DET</td>\n      <td>ATL</td>\n      <td>-4.50</td>\n      <td>4.50</td>\n      <td>-4.50</td>\n      <td>DET</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>20111106_Atlanta_Indianapolis</td>\n      <td>2011-11-06</td>\n      <td>home</td>\n      <td>+103</td>\n      <td>+102</td>\n      <td>-120</td>\n      <td>+7</td>\n      <td>-105</td>\n      <td>-105</td>\n      <td>NaN</td>\n      <td>-105</td>\n      <td>IND</td>\n      <td>ATL</td>\n      <td>6.50</td>\n      <td>-6.50</td>\n      <td>-6.50</td>\n      <td>ATL</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>20111204_Atlanta_Houston</td>\n      <td>2011-12-04</td>\n      <td>home</td>\n      <td>+104</td>\n      <td>-103</td>\n      <td>-110</td>\n      <td>+2</td>\n      <td>-105</td>\n      <td>-105</td>\n      <td>NaN</td>\n      <td>-110</td>\n      <td>HOU</td>\n      <td>ATL</td>\n      <td>1.50</td>\n      <td>-1.50</td>\n      <td>-1.50</td>\n      <td>ATL</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>20111211_Atlanta_Carolina</td>\n      <td>2011-12-11</td>\n      <td>home</td>\n      <td>-119</td>\n      <td>-115</td>\n      <td>-125</td>\n      <td>+3</td>\n      <td>-115</td>\n      <td>+110</td>\n      <td>NaN</td>\n      <td>-120</td>\n      <td>CAR</td>\n      <td>ATL</td>\n      <td>3.00</td>\n      <td>-3.00</td>\n      <td>-3.00</td>\n      <td>ATL</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>20111226_Atlanta_New Orleans</td>\n      <td>2011-12-26</td>\n      <td>home</td>\n      <td>-103</td>\n      <td>-107</td>\n      <td>-110</td>\n      <td>-7.5</td>\n      <td>-105</td>\n      <td>-110</td>\n      <td>NaN</td>\n      <td>-110</td>\n      <td>NO</td>\n      <td>ATL</td>\n      <td>-7.00</td>\n      <td>7.00</td>\n      <td>-7.00</td>\n      <td>NO</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 53
    }
   ],
   "source": [
    "df_ml_home = df_ml[\n",
    "    df_ml['H/A'] == 'home']  # I would do if postive, highest ML, if negative, then number closest to 0.\n",
    "df_ml_away = df_ml[df_ml['H/A'] == 'away']\n",
    "\n",
    "df_ml = df_ml_home.merge(df_ml_away[['key', 'spread']], on=\"key\")\n",
    "df_ml = df_ml.rename(columns={\"spread_x\": \"home_spread\", \"spread_y\": \"away_spread\"})\n",
    "df_ml['date'] = pd.to_datetime(df_ml['date'], format='%Y%m%d')\n",
    "\n",
    "df_ml['spread_favorite'] = np.where(df_ml['home_spread'] >= df_ml['away_spread'], df_ml['away_spread'],\n",
    "                                    df_ml['home_spread'])\n",
    "df_ml['team_favorite_id'] = np.where(df_ml['home_spread'] >= df_ml['away_spread'], df_ml['away'], df_ml['home'])\n",
    "df_ml = df_ml[['date', 'home', 'away', 'team_favorite_id', 'spread_favorite']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "def update_spreads(df, df_spread_update): #updated spread since 2009. Still need a way to get score\n",
    "    df_spread_update = df.merge(df_spread_update,left_on=['schedule_date', 'home', 'away'], right_on=['date', 'home', 'away'], how='left')\n",
    "    df_spread_update = df_spread_update.drop(['spread_favorite_x', 'team_favorite_id_x', 'date'], axis = 1)\n",
    "    df_spread_update = df_spread_update.rename(columns={\"spread_favorite_y\" : \"spread_favorite\", \"team_favorite_id_y\" : \"team_favorite_id\"})\n",
    "    return df_spread_update\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "  schedule_date home  score_home away  score_away team_favorite_id  \\\n0    2009-09-13  ARI        16.0   SF        20.0              ARI   \n1    2009-09-13  ATL        19.0  MIA         7.0              ATL   \n2    2009-09-13  BAL        38.0   KC        24.0              BAL   \n3    2009-09-13  CAR        10.0  PHI        38.0              PHI   \n4    2009-09-13  CIN         7.0  DEN        12.0              CIN   \n5    2009-09-13  CLE        20.0  MIN        34.0              MIN   \n6    2009-09-13   GB        21.0  CHI        15.0              NaN   \n7    2009-09-13  HOU         7.0  NYJ        24.0              HOU   \n8    2009-09-13  IND        14.0  JAX        12.0              NaN   \n9    2009-09-13   NO        45.0  DET        27.0               NO   \n\n   spread_favorite  \n0            -5.00  \n1            -4.00  \n2           -13.00  \n3            -2.50  \n4            -4.75  \n5            -4.00  \n6              NaN  \n7            -4.50  \n8              NaN  \n9           -14.00  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>schedule_date</th>\n      <th>home</th>\n      <th>score_home</th>\n      <th>away</th>\n      <th>score_away</th>\n      <th>team_favorite_id</th>\n      <th>spread_favorite</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2009-09-13</td>\n      <td>ARI</td>\n      <td>16.0</td>\n      <td>SF</td>\n      <td>20.0</td>\n      <td>ARI</td>\n      <td>-5.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2009-09-13</td>\n      <td>ATL</td>\n      <td>19.0</td>\n      <td>MIA</td>\n      <td>7.0</td>\n      <td>ATL</td>\n      <td>-4.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2009-09-13</td>\n      <td>BAL</td>\n      <td>38.0</td>\n      <td>KC</td>\n      <td>24.0</td>\n      <td>BAL</td>\n      <td>-13.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2009-09-13</td>\n      <td>CAR</td>\n      <td>10.0</td>\n      <td>PHI</td>\n      <td>38.0</td>\n      <td>PHI</td>\n      <td>-2.50</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2009-09-13</td>\n      <td>CIN</td>\n      <td>7.0</td>\n      <td>DEN</td>\n      <td>12.0</td>\n      <td>CIN</td>\n      <td>-4.75</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2009-09-13</td>\n      <td>CLE</td>\n      <td>20.0</td>\n      <td>MIN</td>\n      <td>34.0</td>\n      <td>MIN</td>\n      <td>-4.00</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2009-09-13</td>\n      <td>GB</td>\n      <td>21.0</td>\n      <td>CHI</td>\n      <td>15.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2009-09-13</td>\n      <td>HOU</td>\n      <td>7.0</td>\n      <td>NYJ</td>\n      <td>24.0</td>\n      <td>HOU</td>\n      <td>-4.50</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2009-09-13</td>\n      <td>IND</td>\n      <td>14.0</td>\n      <td>JAX</td>\n      <td>12.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2009-09-13</td>\n      <td>NO</td>\n      <td>45.0</td>\n      <td>DET</td>\n      <td>27.0</td>\n      <td>NO</td>\n      <td>-14.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 75
    }
   ],
   "source": [
    "df_test2 = update_spreads(df, df_ml)\n",
    "df_test2.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}